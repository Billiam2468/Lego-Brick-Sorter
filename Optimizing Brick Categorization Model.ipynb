{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa9aebe0",
   "metadata": {},
   "source": [
    "# This is the notebook for optimizing the model for categorizing our Lego bricks. Categories will be defined by Tom Alphin's Lego Brick Labels (v39)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9e5bc457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1e93b19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-313.1723, shape=(), dtype=float32)\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822fadc",
   "metadata": {},
   "source": [
    "# Comparing Transfer Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c645824f",
   "metadata": {},
   "source": [
    "We will be using transfer learning techniques on Keras pre-trained models to create our categorization model. We will first need to test out all of the different Keras Applications and discover which one will best work for our needs.\n",
    "\n",
    "\n",
    "\n",
    "**Training Dataset:**\n",
    "\n",
    "We will be using the 447 class training data set referenced in this paper:https://www.iccs-meeting.org/archive/iccs2022/papers/133520608.pdf\n",
    "\n",
    "**Testing:**\n",
    "\n",
    "We will be selecting 20 random classes of Lego brick to train our models on. Models will then be compared with each other to determine what will best work for our purposes\n",
    "\n",
    "**Data Augmentation:**\n",
    "\n",
    "In order to save time for finding an optimal model, no data augmentation other than resizing our images (without preserving aspect ratio) to match the input of the models will be utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "663e295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of models we will test\n",
    "model_dict = {}\n",
    "model_dict[\"VGG16\"] = tf.keras.applications.VGG16\n",
    "model_dict[\"VGG19\"] = tf.keras.applications.VGG19\n",
    "model_dict[\"ResNet101V2\"] = tf.keras.applications.ResNet101V2\n",
    "# model_dict[\"ResNet152\"] = tf.keras.applications.ResNet152\n",
    "model_dict[\"ResNet152V2\"] = tf.keras.applications.ResNet152V2\n",
    "model_dict[\"ResNet50\"] = tf.keras.applications.ResNet50\n",
    "model_dict[\"ResNet50V2\"] = tf.keras.applications.ResNet50V2\n",
    "model_dict[\"InceptionResNetV2\"] = tf.keras.applications.InceptionResNetV2\n",
    "model_dict[\"InceptionV3\"] = tf.keras.applications.InceptionV3\n",
    "model_dict[\"MobileNet\"] = tf.keras.applications.MobileNet\n",
    "model_dict[\"MobileNetV2\"] = tf.keras.applications.MobileNetV2\n",
    "# model_dict[\"MobileNetV3\"] = tf.keras.applications.MobileNetV3 <- weird exceptions\n",
    "model_dict[\"Xception\"] = tf.keras.applications.Xception\n",
    "model_dict[\"DenseNet121\"] = tf.keras.applications.DenseNet121\n",
    "model_dict[\"DenseNet169\"] = tf.keras.applications.DenseNet169\n",
    "model_dict[\"DenseNet201\"] = tf.keras.applications.DenseNet201\n",
    "model_dict[\"EfficientNetV2S\"] = tf.keras.applications.EfficientNetV2S\n",
    "model_dict[\"EfficientNetV2M\"] = tf.keras.applications.EfficientNetV2M\n",
    "model_dict[\"EfficientNetV2L\"] = tf.keras.applications.EfficientNetV2L\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7063c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▌                                                         | 1/17 [00:00<00:02,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: VGG16\n",
      "Processing: VGG19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|███████▏                                                     | 2/17 [00:00<00:03,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ResNet101V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████▊                                                  | 3/17 [00:01<00:11,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ResNet152V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████▎                                              | 4/17 [00:04<00:17,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|█████████████████▉                                           | 5/17 [00:04<00:13,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ResNet50V2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|█████████████████████▌                                       | 6/17 [00:05<00:11,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: InceptionResNetV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████                                    | 7/17 [00:08<00:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: InceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████▋                                | 8/17 [00:09<00:13,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: MobileNet\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████▎                            | 9/17 [00:10<00:09,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: MobileNetV2\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████▎                        | 10/17 [00:10<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Xception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████████████████████████████████████▊                     | 11/17 [00:11<00:05,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: DenseNet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|██████████████████████████████████████████▎                 | 12/17 [00:13<00:05,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: DenseNet169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████▉              | 13/17 [00:16<00:06,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: DenseNet201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████▍          | 14/17 [00:18<00:05,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EfficientNetV2S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████████████████████████████████████████████████▉       | 15/17 [00:20<00:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EfficientNetV2M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|████████████████████████████████████████████████████████▍   | 16/17 [00:24<00:02,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EfficientNetV2L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 17/17 [00:28<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load in our preprocessed models into a dictionary\n",
    "preprocessed_models = {}\n",
    "for model_name, model in tqdm(model_dict.items()):\n",
    "    print(\"Processing: \" + model_name)\n",
    "    preprocessed_models[model_name] = model(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9080c73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: VGG16\n",
      "Model: \"sequential_126\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "processing: VGG19\n",
      "Model: \"sequential_127\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n",
      "processing: ResNet101V2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2_block1_out\" (type Add).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, None, None, 256), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"conv2_block1_out\" (type Add):\n  • inputs=tf.Tensor(shape=(None, None, None, 256), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Doing include_top = false instead\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Add all layers from our pre-trained model (last layer already deleted)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m pre_model\u001b[38;5;241m.\u001b[39mlayers[:]:\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Make all remaining layers untrainable and add our last trainable layer\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/layers/merging/base_merge.py:123\u001b[0m, in \u001b[0;36m_Merge.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA merge layer should be called on a list of inputs. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: inputs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (not a list of tensors)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         )\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reshape_required:\n\u001b[1;32m    128\u001b[0m         reshaped_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2_block1_out\" (type Add).\n\nA merge layer should be called on a list of inputs. Received: inputs=Tensor(\"Placeholder:0\", shape=(None, None, None, 256), dtype=float32) (not a list of tensors)\n\nCall arguments received by layer \"conv2_block1_out\" (type Add):\n  • inputs=tf.Tensor(shape=(None, None, None, 256), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Process our models\n",
    "# (delete the last layer, make all remaining layers untrainable, and add our own trainable layer)\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "processed_models = {}\n",
    "for name, pre_model in preprocessed_models.items():\n",
    "    print(\"processing: \" + name)\n",
    "    # Create our empty model (look up sequential vs functional)\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    # Doing include_top = false instead\n",
    "    # Add all layers from our pre-trained model (last layer already deleted)\n",
    "    for layer in pre_model.layers[:]:\n",
    "        model.add(layer)\n",
    "\n",
    "    # Make all remaining layers untrainable and add our last trainable layer\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model.summary()\n",
    "        \n",
    "    model.add(layers.Dense(NUM_CLASSES))\n",
    "    \n",
    "    # Loss and optimizer functions\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    # Might try mean average precision for metric because we are categorizing so many classes\n",
    "    metrics = [\"accuracy\"]\n",
    "    \n",
    "    # Used to do accuracy but someone online recommended MAP\n",
    "    # https://www.reddit.com/r/learnmachinelearning/comments/xpyv8j/data_set_for_lego_image_classification_800000/\n",
    "    # metrics = [\"accuracy\"]\n",
    "\n",
    "    # Compile our model\n",
    "    model.compile(optimizer=optim, loss=loss, metrics=metrics)\n",
    "    \n",
    "    # Add model to our dict\n",
    "    processed_models[name] = model\n",
    "processed_models[\"VGG16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "952d7650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8463 images belonging to 5 classes.\n",
      "Found 3528 images belonging to 5 classes.\n",
      "Found 2115 images belonging to 5 classes.\n",
      "Start training of: VGG16\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_61881/3492864896.py\", line 72, in <module>\n      model.fit(train_batches, validation_data=val_batches,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 998, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 700, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n      matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 970, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_440655]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 72\u001b[0m\n\u001b[1;32m     65\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     66\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     68\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     69\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart training of: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name)\n\u001b[0;32m---> 72\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_batches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerformance of\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_batches, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 728, in start\n      self.io_loop.start()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/base_events.py\", line 1899, in _run_once\n      handle._run()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 423, in do_execute\n      res = shell.run_cell(\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_61881/3492864896.py\", line 72, in <module>\n      model.fit(train_batches, validation_data=val_batches,\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 998, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/training.py\", line 1092, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 143, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/base_metric.py\", line 700, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/metrics/metrics.py\", line 3669, in sparse_categorical_accuracy\n      matches = metrics_utils.sparse_categorical_matches(y_true, y_pred)\n    File \"/home/billiam/miniconda3/envs/tf/lib/python3.10/site-packages/keras/utils/metrics_utils.py\", line 970, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nrequired broadcastable shapes\n\t [[{{node Equal}}]] [Op:__inference_train_function_440655]"
     ]
    }
   ],
   "source": [
    "# Generate tensor image data batches with model specific preprocessing\n",
    "BASE_DIR = 'images/'\n",
    "names = [\"3003\", \"3004\", \"3021\", \"6091\", \"852929\"]\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "ppDict = {}\n",
    "ppDict[\"VGG16\"] = tf.keras.applications.vgg16.preprocess_input\n",
    "ppDict[\"VGG19\"] = tf.keras.applications.vgg19.preprocess_input\n",
    "ppDict[\"ResNet101V2\"] = tf.keras.applications.resnet_v2.preprocess_input\n",
    "ppDict[\"ResNet152V2\"] = tf.keras.applications.resnet_v2.preprocess_input\n",
    "ppDict[\"ResNet50\"] = tf.keras.applications.resnet50.preprocess_input\n",
    "ppDict[\"ResNet50V2\"] = tf.keras.applications.resnet_v2.preprocess_input\n",
    "ppDict[\"InceptionResNetV2\"] = tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "ppDict[\"InceptionV3\"] = tf.keras.applications.inception_v3.preprocess_input\n",
    "ppDict[\"MobileNet\"] = tf.keras.applications.mobilenet.preprocess_input\n",
    "ppDict[\"MobileNetV2\"] = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "ppDict[\"Xception\"] = tf.keras.applications.xception.preprocess_input\n",
    "ppDict[\"DenseNet121\"] = tf.keras.applications.densenet.preprocess_input\n",
    "ppDict[\"DenseNet169\"] = tf.keras.applications.densenet.preprocess_input\n",
    "ppDict[\"DenseNet201\"] = tf.keras.applications.densenet.preprocess_input\n",
    "ppDict[\"EfficientNetV2S\"] = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "ppDict[\"EfficientNetV2M\"] = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "ppDict[\"EfficientNetV2L\"] = tf.keras.applications.efficientnet_v2.preprocess_input\n",
    "\n",
    "fitModels = {}\n",
    "\n",
    "for name, model in processed_models.items():\n",
    "    train_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=ppDict[name])\n",
    "    valid_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=ppDict[name])\n",
    "    test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=ppDict[name])\n",
    "    \n",
    "    train_batches = train_gen.flow_from_directory(\n",
    "        BASE_DIR + 'train',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='sparse',\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=names   \n",
    "    )\n",
    "\n",
    "    val_batches = valid_gen.flow_from_directory(\n",
    "        BASE_DIR + 'val',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='sparse',\n",
    "        batch_size=4,\n",
    "        shuffle=True,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=names\n",
    "    )\n",
    "\n",
    "    test_batches = test_gen.flow_from_directory(\n",
    "        BASE_DIR + 'test',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='sparse',\n",
    "        batch_size=4,\n",
    "        shuffle=False,\n",
    "        color_mode=\"rgb\",\n",
    "        classes=names\n",
    "    )\n",
    "    \n",
    "    epochs = 30\n",
    "    \n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Start training of: \" + name)\n",
    "    model.fit(train_batches, validation_data=val_batches,\n",
    "              callbacks=[early_stopping],\n",
    "              epochs=epochs, verbose=2)\n",
    "    print(\"Performance of\" + name + \": \")\n",
    "    model.evaluate(test_batches, verbose=2)\n",
    "    \n",
    "    \n",
    "    fitModels[name] = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a53d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
