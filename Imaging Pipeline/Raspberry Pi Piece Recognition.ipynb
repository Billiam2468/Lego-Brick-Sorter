{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6ec3ea",
   "metadata": {},
   "source": [
    "This is the code that will be imported into our Raspberry Pi to process and send images to our computer for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48242ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '6091', '3021', '3003']\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "\n",
    "# reload our external packages (tracker)\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage import data, filters\n",
    "import tracker as track\n",
    "\n",
    "importlib.reload(track)\n",
    "\n",
    "# Directory to save training images\n",
    "base_dir = \"/Users/williamlee/Documents/Git Repos/Lego-Brick-Sorter/realData\"\n",
    "os.chdir(base_dir)\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f778e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-45be95bf43c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(\"in loop\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Capture video frame by frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pieceNum = \"3021\"\n",
    "os.chdir(pieceNum)\n",
    "# Open Video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create Tracker Object\n",
    "tracker = track.EuclideanDistTracker()\n",
    "\n",
    "# Create BG Subtraction Function\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "\n",
    "# Create Window\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# FOR TRAINING:\n",
    "num_img = 0\n",
    "\n",
    "while(True):\n",
    "    # print(\"in loop\")\n",
    "    # Capture video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # 0: Pre-Process Image\n",
    "    window_factor = 0.5       # Size factor of display window\n",
    "    x_left_crop = 400        # Left side window crop\n",
    "    x_right_crop = 1920     # Right side window crop\n",
    "    y_top_crop = 0          # Top side window crop\n",
    "    y_bottom_crop = 1080    # Bottom side window crop\n",
    "    saturation_factor = 1 # Factor to saturate image by\n",
    "    value_factor = 1.2      # Factor to increase value of image by\n",
    "\n",
    "    # Crop and adjust saturation of image\n",
    "    frame = frame[y_top_crop:y_bottom_crop, x_left_crop:x_right_crop]\n",
    "    adjusted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "    (h, s, v) = cv2.split(adjusted)\n",
    "    s = s * saturation_factor\n",
    "    s = np.clip(s,0,255)\n",
    "    v = v * value_factor\n",
    "    v = np.clip(v,0,255)\n",
    "    adjusted = cv2.merge([h,s,v])\n",
    "    frame = cv2.cvtColor(adjusted.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Apply MOG2 to Frame\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Adjust size\n",
    "    frame = cv2.resize(frame, None, fx=window_factor, fy=window_factor, interpolation=cv2.INTER_AREA)\n",
    "    fgmask = cv2.resize(fgmask, None, fx=window_factor, fy=window_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "    # 1: Object Detection\n",
    "    min_area = 300 # Min area of contour to detect as piece\n",
    "    \n",
    "    # Iterate through discovered contours and add detections\n",
    "    contours, hierarchy = cv2.findContours(image=fgmask, mode=cv2.RETR_CCOMP, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    image_copy = frame.copy()\n",
    "    for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            # If contour overlap with border then skip\n",
    "            if((x == 0) or (y == 0) or (x+w >= frame.shape[1]) or (y+h >= frame.shape[0])):\n",
    "                continue\n",
    "            \n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > min_area):\n",
    "                detections.append([x, y, w, h])\n",
    "                \n",
    "                \n",
    "    # 2: Object Tracking\n",
    "    min_age = 5 # Min age of object to classify as brick\n",
    "    interval = 1 # Frequency of images to save after being classified as brick\n",
    "    \n",
    "    box_ids = tracker.update(detections)\n",
    "    for box_id in box_ids:\n",
    "        x, y, w, h, id, age = box_id\n",
    "        # If a box is \"old enough\" box is determined to be a piece --> take pictures\n",
    "        if age > min_age:\n",
    "            num_img += 1\n",
    "            larger = w\n",
    "            if(h > w):\n",
    "                larger = h\n",
    "            cv2.rectangle(image_copy, (x,y), (x+larger, y+larger), (0, 255, 0), 3)\n",
    "            cv2.putText(image_copy, \"PIECE IS HERE\" + \" time:\" + str(age),(x,y-10),0,0.5,(255, 0, 0), 2)\n",
    "            \n",
    "            # Save bounding box as image every X frames\n",
    "            roi = frame[y:y+larger, x:x+larger]\n",
    "            #print(str(num_img) + \".jpg\")\n",
    "            true_age = age - min_age\n",
    "            if(true_age % interval == 0):\n",
    "                print(true_age)\n",
    "                #print(\"save image\")\n",
    "                cv2.imwrite(str(num_img) + \".png\", roi)\n",
    "            \n",
    "    \n",
    "    cv2.imshow('Feed with bounding boxes', image_copy)\n",
    "    cv2.imshow('MOG2 Output', fgmask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f5a3809",
   "metadata": {},
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create Tracker Object\n",
    "tracker = track.EuclideanDistTracker()\n",
    "\n",
    "# Create BG Subtraction Function\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "\n",
    "# Create Window\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# FOR TRAINING:\n",
    "num_img = 0\n",
    "\n",
    "while(True):\n",
    "    # print(\"in loop\")\n",
    "    # Capture video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # 0: Pre-Process Image\n",
    "    window_factor = 0.5   # Size factor of display window\n",
    "    x_left_crop = 210     # Left side window crop\n",
    "    x_right_crop = 1920   # Right side window crop\n",
    "    y_top_crop = 0        # Top side window crop\n",
    "    y_bottom_crop = 1080  # Bottom side window crop\n",
    "    saturation_factor = 1 # Factor to saturate image by\n",
    "    value_factor = 1.5    # Factor to increase value by\n",
    "\n",
    "    # Crop and adjust saturation of image\n",
    "    frame = frame[y_top_crop:y_bottom_crop, x_left_crop:x_right_crop]\n",
    "    adjusted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "    (h, s, v) = cv2.split(adjusted)\n",
    "    s = s * saturation_factor\n",
    "    v = v * value_factor\n",
    "    s = np.clip(s,0,255)\n",
    "    v = np.clip(v,0,255)\n",
    "    adjusted = cv2.merge([h,s,v])\n",
    "    frame = cv2.cvtColor(adjusted.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Apply MOG2 to Frame\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Adjust size\n",
    "    frame = cv2.resize(frame, None, fx=window_factor, fy=window_factor, interpolation=cv2.INTER_AREA)\n",
    "    fgmask = cv2.resize(fgmask, None, fx=window_factor, fy=window_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    \n",
    "    # 1: Object Detection\n",
    "    min_area = 300 # Min area of contour to detect as piece\n",
    "    \n",
    "    # Iterate through discovered contours and add detections\n",
    "    contours, hierarchy = cv2.findContours(image=fgmask, mode=cv2.RETR_CCOMP, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    image_copy = frame.copy()\n",
    "    for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > min_area):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                #cv2.putText(image_copy, \"area: \" + str(area),(x,y-10),0,0.5,(255, 0, 0), 2)\n",
    "                detections.append([x, y, w, h])\n",
    "                \n",
    "                larger = w\n",
    "                if(h > w):\n",
    "                    larger = h\n",
    "                cv2.rectangle(image_copy, (x,y), (x+larger, y+larger), (0, 255, 0), 3)\n",
    "                cv2.putText(image_copy, \"PIECE IS HERE\" + \" time:\" + str(area),(x,y-10),0,0.5,(255, 0, 0), 2)\n",
    "                roi = frame[y:y+larger, x:x+larger]\n",
    "                #cv2.imwrite(str(num_img) + \".jpg\", roi)\n",
    "\n",
    "                \n",
    "#     # 2: Object Tracking\n",
    "#     min_age = -1 # Min age of object to classify as brick\n",
    "#     interval = 1 # Frequency of images to save after being classified as brick\n",
    "    \n",
    "#     box_ids = tracker.update(detections)\n",
    "#     for box_id in box_ids:\n",
    "#         x, y, w, h, id, age = box_id\n",
    "#         # If a box is \"old enough\" box is determined to be a piece --> take pictures\n",
    "#         if age > min_age:\n",
    "#             num_img += 1\n",
    "#             larger = w\n",
    "#             if(h > w):\n",
    "#                 larger = h\n",
    "#             cv2.rectangle(image_copy, (x,y), (x+larger, y+larger), (0, 255, 0), 3)\n",
    "#             cv2.putText(image_copy, \"PIECE IS HERE\" + \" time:\" + str(age),(x,y-10),0,0.5,(255, 0, 0), 2)\n",
    "            \n",
    "#             # Save bounding box as image every X frames\n",
    "#             roi = frame[y:y+larger, x:x+larger]\n",
    "#             #print(str(num_img) + \".jpg\")\n",
    "#             true_age = age - min_age\n",
    "#             if(true_age % interval == 0):\n",
    "#                 print(true_age)\n",
    "#                 print(\"save image\")\n",
    "#                 #cv2.imwrite(str(num_img) + \".jpg\", roi)\n",
    "            \n",
    "    \n",
    "    cv2.imshow('Feed with bounding boxes', image_copy)\n",
    "    cv2.imshow('MOG2 Output', fgmask)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eff3aaaf",
   "metadata": {},
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 3) # auto mode\n",
    "cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 1) # manual mode\n",
    "cap.set(cv2.CAP_PROP_EXPOSURE, 50)\n",
    "# Create Window\n",
    "cv2.startWindowThread()\n",
    "\n",
    "# FOR TRAINING:\n",
    "num_img = 0\n",
    "\n",
    "while(True):\n",
    "    # print(\"in loop\")\n",
    "    # Capture video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('MOG2 Output', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e71b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
