{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b6ec3ea",
   "metadata": {},
   "source": [
    "This is the code that will be imported into our Raspberry Pi to process and send images to our computer for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48242ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "# reload our external packages (tracker)\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import data, filters\n",
    "import tracker as track\n",
    "\n",
    "importlib.reload(track)\n",
    "\n",
    "#IMAGE SETTINGS:\n",
    "x_left_crop = 150\n",
    "x_right_crop = 1750\n",
    "y_top_crop = 200\n",
    "y_bottom_crop = 850\n",
    "saturation_factor = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f778e8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2b1072839ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Crop and adjust image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_top_crop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_bottom_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_left_crop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_right_crop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0madjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjusted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create Tracker Object\n",
    "tracker = track.EuclideanDistTracker()\n",
    "\n",
    "# Create BG Subtraction Function\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "\n",
    "# Create Window\n",
    "cv2.startWindowThread()\n",
    "\n",
    "while(cv2.waitKey(1) != 27):\n",
    "    # Capture video frame by frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Crop and adjust image\n",
    "    frame = frame[y_top_crop:y_bottom_crop, x_left_crop:x_right_crop]\n",
    "    adjusted = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV).astype(\"float32\")\n",
    "    (h, s, v) = cv2.split(adjusted)\n",
    "    s = s * saturation_factor\n",
    "    s = np.clip(s,0,255)\n",
    "    adjusted = cv2.merge([h,s,v])\n",
    "    frame = cv2.cvtColor(adjusted.astype(\"uint8\"), cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "\n",
    "    # Apply MOG2 to Frame\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    # Adjust size\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "    fgmask = cv2.resize(fgmask, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 1: Object Detection\n",
    "    \n",
    "    # Iterate through discovered contours and add detections\n",
    "    contours, hierarchy = cv2.findContours(image=fgmask, mode=cv2.RETR_CCOMP, method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "    detections = []\n",
    "    image_copy = frame.copy()\n",
    "    for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if(area > 100):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                detections.append([x, y, w, h])\n",
    "\n",
    "    # 2: Object Tracking            \n",
    "    box_ids = tracker.update(detections)\n",
    "    for box_id in box_ids:\n",
    "        x, y, w, h, id, time = box_id\n",
    "        # If a condition is met (box determined to be a piece, take and save several pictures of it)\n",
    "        if time > 20:\n",
    "            cv2.rectangle(image_copy, (x,y), (x+w, y+h), (0, 255, 0), 3)\n",
    "            cv2.putText(image_copy, \"PIECE IS HERE\" + \" time:\" + str(time),(x,y-10),0,0.5,(255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('FG Mask', image_copy)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc3e2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9ed70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
