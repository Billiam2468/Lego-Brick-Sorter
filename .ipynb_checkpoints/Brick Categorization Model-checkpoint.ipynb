{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba4a958",
   "metadata": {},
   "source": [
    "# Model Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049de516",
   "metadata": {},
   "source": [
    "This notebook will take our image located at base directory, train a model, and then test the performance of that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0d906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import os  \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a59a1e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(171.85776, shape=(), dtype=float32)\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/home/billiam/Documents/Repos/Lego-Brick-Sorter\n"
     ]
    }
   ],
   "source": [
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "os.chdir(\"/home/billiam/Documents/Repos/Lego-Brick-Sorter\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aa1a7a",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**DISTRIBUTE IMAGES TO TRAINING, VALIDATION, AND TEST FOLDERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bca9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = 'data/'\n",
    "names = [\"3003\", \"3004\", \"3021\", \"6091\"]\n",
    "percentTraining = 0.75\n",
    "percentValidation = 0.25\n",
    "\n",
    "#Test set is defined as 0% since we will be using our own real images to test model in end, rather than synthetic data\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed24eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 750 250 0\n",
      "1000 750 250 0\n",
      "1000 750 250 0\n",
      "1000 750 250 0\n"
     ]
    }
   ],
   "source": [
    "# Reorganize the folder structure:\n",
    "if not os.path.isdir(BASE_DIR + 'train/'):\n",
    "    for name in names:\n",
    "        os.makedirs(BASE_DIR + 'train/' + name)\n",
    "        os.makedirs(BASE_DIR + 'val/' + name)\n",
    "        os.makedirs(BASE_DIR + 'test/' + name)\n",
    "        \n",
    "# Move the image files\n",
    "orig_folders = [name + \"/\" for name in names]\n",
    "for folder_idx, folder in enumerate(orig_folders):\n",
    "    files = os.listdir(BASE_DIR + folder)\n",
    "    number_of_images = len([name for name in files])\n",
    "    n_train = int((number_of_images * percentTraining) + 0.5)\n",
    "    n_valid = int((number_of_images* percentValidation) + 0.5)\n",
    "    n_test = number_of_images - n_train - n_valid\n",
    "    print(number_of_images, n_train, n_valid, n_test)\n",
    "    for idx, file in enumerate(files):\n",
    "        file_name = BASE_DIR + folder + file\n",
    "        if idx < n_train:\n",
    "            shutil.move(file_name, BASE_DIR + \"train/\" + names[folder_idx])\n",
    "        elif idx < n_train + n_valid:\n",
    "            shutil.move(file_name, BASE_DIR + \"val/\" + names[folder_idx])\n",
    "        else:\n",
    "            shutil.move(file_name, BASE_DIR + \"test/\" + names[folder_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eecf21",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**CREATE OUR PRE-TRAINED MODEL WITH ONLY A FINAL TRAINABLE LAYER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce2e831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From our previous test (447 5 class data set, our best performer was DenseNet169, so will use that here)\n",
    "pre_model = tf.keras.applications.DenseNet169(include_top=False)\n",
    "preprocess_fxn = tf.keras.applications.densenet.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef616210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, None, None, 1664)  12642880  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1664)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 6660      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,649,540\n",
      "Trainable params: 6,660\n",
      "Non-trainable params: 12,642,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile our pre-trained model without last layer with a single trainable final layer\n",
    "\n",
    "NUM_CLASSES = len(names)\n",
    "\n",
    "# Create our empty model (look up sequential vs functional)\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Add all layers from our pre-trained model (last layer already deleted from include_top=False)\n",
    "model.add(pre_model)\n",
    "\n",
    "# Make all remaining layers untrainable and add our last trainable layer\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(NUM_CLASSES))\n",
    "\n",
    "# Loss and optimizer functions\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Might try mean average precision for metric because we are categorizing so many classes\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# Used to do accuracy but someone online recommended MAP\n",
    "# https://www.reddit.com/r/learnmachinelearning/comments/xpyv8j/data_set_for_lego_image_classification_800000/\n",
    "# metrics = [\"accuracy\"]\n",
    "\n",
    "# Compile our model\n",
    "model.compile(optimizer=optim, loss=loss, metrics=metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4784c7b",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "**CREATE TENSORFLOW IMAGE DATA BATCHES WITH PREPROCESSING AND TRAIN OUR MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36626a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 4 classes.\n",
      "Found 1000 images belonging to 4 classes.\n",
      "Found 0 images belonging to 4 classes.\n",
      "Start training of: 6091\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet169 (Functional)    (None, None, None, 1664)  12642880  \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1664)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 6660      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,649,540\n",
      "Trainable params: 6,660\n",
      "Non-trainable params: 12,642,880\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "750/750 - 36s - loss: 0.3654 - accuracy: 0.8680 - val_loss: 0.1743 - val_accuracy: 0.9470 - 36s/epoch - 47ms/step\n",
      "Epoch 2/30\n",
      "750/750 - 27s - loss: 0.1270 - accuracy: 0.9647 - val_loss: 0.1253 - val_accuracy: 0.9620 - 27s/epoch - 36ms/step\n",
      "Epoch 3/30\n",
      "750/750 - 27s - loss: 0.0863 - accuracy: 0.9787 - val_loss: 0.0925 - val_accuracy: 0.9770 - 27s/epoch - 37ms/step\n",
      "Epoch 4/30\n",
      "750/750 - 27s - loss: 0.0647 - accuracy: 0.9830 - val_loss: 0.0848 - val_accuracy: 0.9750 - 27s/epoch - 36ms/step\n",
      "Epoch 5/30\n",
      "750/750 - 27s - loss: 0.0515 - accuracy: 0.9873 - val_loss: 0.0759 - val_accuracy: 0.9760 - 27s/epoch - 36ms/step\n",
      "Epoch 6/30\n",
      "750/750 - 27s - loss: 0.0378 - accuracy: 0.9933 - val_loss: 0.0772 - val_accuracy: 0.9750 - 27s/epoch - 36ms/step\n",
      "Epoch 7/30\n",
      "750/750 - 27s - loss: 0.0301 - accuracy: 0.9940 - val_loss: 0.0813 - val_accuracy: 0.9700 - 27s/epoch - 36ms/step\n",
      "Epoch 8/30\n",
      "750/750 - 27s - loss: 0.0238 - accuracy: 0.9970 - val_loss: 0.0652 - val_accuracy: 0.9790 - 27s/epoch - 36ms/step\n",
      "Epoch 9/30\n",
      "750/750 - 27s - loss: 0.0198 - accuracy: 0.9977 - val_loss: 0.0646 - val_accuracy: 0.9750 - 27s/epoch - 36ms/step\n",
      "Epoch 10/30\n",
      "750/750 - 27s - loss: 0.0159 - accuracy: 0.9983 - val_loss: 0.0764 - val_accuracy: 0.9720 - 27s/epoch - 36ms/step\n",
      "Epoch 11/30\n",
      "750/750 - 27s - loss: 0.0138 - accuracy: 0.9993 - val_loss: 0.0784 - val_accuracy: 0.9720 - 27s/epoch - 36ms/step\n",
      "Epoch 12/30\n",
      "750/750 - 27s - loss: 0.0129 - accuracy: 0.9983 - val_loss: 0.0609 - val_accuracy: 0.9780 - 27s/epoch - 36ms/step\n",
      "Epoch 13/30\n",
      "750/750 - 27s - loss: 0.0103 - accuracy: 0.9997 - val_loss: 0.0631 - val_accuracy: 0.9740 - 27s/epoch - 36ms/step\n",
      "Epoch 14/30\n",
      "750/750 - 27s - loss: 0.0076 - accuracy: 0.9997 - val_loss: 0.0797 - val_accuracy: 0.9750 - 27s/epoch - 36ms/step\n",
      "Epoch 15/30\n",
      "750/750 - 27s - loss: 0.0073 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9750 - 27s/epoch - 36ms/step\n",
      "Epoch 16/30\n",
      "750/750 - 27s - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0658 - val_accuracy: 0.9800 - 27s/epoch - 35ms/step\n",
      "Epoch 17/30\n",
      "750/750 - 27s - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0849 - val_accuracy: 0.9730 - 27s/epoch - 36ms/step\n",
      "Epoch 17: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f967062b040>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_fxn)\n",
    "valid_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_fxn)\n",
    "test_gen = keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_fxn)\n",
    "\n",
    "train_batches = train_gen.flow_from_directory(\n",
    "    BASE_DIR + 'train',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='sparse',\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names   \n",
    ")\n",
    "\n",
    "val_batches = valid_gen.flow_from_directory(\n",
    "    BASE_DIR + 'val',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='sparse',\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "test_batches = test_gen.flow_from_directory(\n",
    "    BASE_DIR + 'test',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='sparse',\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    color_mode=\"rgb\",\n",
    "    classes=names\n",
    ")\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "print(\"Start training of: \" + name)\n",
    "model.summary()\n",
    "model.fit(train_batches, validation_data=val_batches,\n",
    "          callbacks=[early_stopping],\n",
    "          epochs=epochs, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cca21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance of\" + name + \": \")\n",
    "model.evaluate(test_batches, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
